{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import scipy.misc\n",
    "from skimage.morphology import label\n",
    "import skimage\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_CHANNELS = 3\n",
    "DATA = {\n",
    "    'TRAIN': '../data/train/',\n",
    "    'TEST': '../data/test/'\n",
    "}\n",
    "\n",
    "train_paths = glob(os.path.join(DATA['TRAIN'], '*'))\n",
    "test_paths = glob(os.path.join(DATA['TEST'], '*'))\n",
    "\n",
    "MASK_POSTFIX = 'mask_ibn'\n",
    "seed = 42\n",
    "P_THRESHOLD = .5\n",
    "BATCH_SIZE = 16\n",
    "SIDE = 256\n",
    "STEP = SIDE // 4\n",
    "\n",
    "# Amount of categories predicted per pixels.\n",
    "nb_classes = 1\n",
    "\n",
    "np.random.seed = seed\n",
    "\n",
    "SPLIT = .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(path, test_mode=False):\n",
    "    im = scipy.misc.imread(os.path.join(path, 'images', os.path.basename(path) + '.png'))[..., :IMG_CHANNELS]\n",
    "    \n",
    "    if im.std(-1).sum() > 10:\n",
    "        im = (im - im.min((0, 1))) / (im.max((0, 1)) - im.min((0, 1)))\n",
    "        im = np.abs(im.astype(np.float).mean(-1) - 1.)\n",
    "    else:\n",
    "        im = im[..., 0].astype(np.float)\n",
    "        im = (im - im.min()) / (im.max() - im.min())\n",
    "    \n",
    "    if test_mode:\n",
    "        return im\n",
    "    \n",
    "    return np.dstack([\n",
    "        im,\n",
    "        np.load(os.path.join(path, MASK_POSTFIX + '.npy')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 670/670 [00:03<00:00, 212.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 65/65 [00:00<00:00, 173.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# std_paths = list()\n",
    "# for n, path in tqdm(enumerate(train_paths), total=len(train_paths)):\n",
    "#     img = imread(os.path.join(path, 'images', os.path.basename(path) + '.png'))[..., :IMG_CHANNELS]\n",
    "#     mask = list()\n",
    "#     for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "#         mask.append(imread(path + '/masks/' + mask_file))\n",
    "#     std_paths.append((path, img.std(-1).sum(), len(mask)))\n",
    "#     mask = np.array(mask).max(0)\n",
    "#     np.save(path + '/mask', mask)\n",
    "\n",
    "\n",
    "# std_paths = list()\n",
    "# for n, path in tqdm(enumerate(test_paths), total=len(test_paths)):\n",
    "#     img = scipy.misc.imread(os.path.join(path, 'images', os.path.basename(path) + '.png'))[..., :IMG_CHANNELS]\n",
    "#     std_paths.append((path, img.std(-1).sum()))\n",
    "\n",
    "\n",
    "# for n, path in tqdm(enumerate(train_paths), total=len(train_paths)):\n",
    "#     mask = list()\n",
    "#     for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "#         im = scipy.misc.imread(path + '/masks/' + mask_file)\n",
    "#         im = scipy.ndimage.distance_transform_edt(im)\n",
    "#         im[im == 0] = 1e+7\n",
    "#         mask.append(im)\n",
    "#     mask = np.array(mask).min(0)\n",
    "#     mask[mask == 1e+7] = 0\n",
    "#     mask[scipy.ndimage.binary_dilation((mask == 1), iterations=2) & np.logical_not(mask >= 1.1)] = -1\n",
    "#     mask[mask > 0] = 1\n",
    "#     np.save(path + '/mask_edt_bn', mask)\n",
    "\n",
    "\n",
    "# for n, path in tqdm(enumerate(train_paths), total=len(train_paths)):\n",
    "#     masks = list()\n",
    "#     for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "#         masks.append(scipy.misc.imread(path + '/masks/' + mask_file) > 0)\n",
    "#     mask = np.array(masks).max(0)\n",
    "#     imask = mask.copy().astype(np.float)\n",
    "#     borders = np.zeros(np.array(imask.shape) - 4, dtype=np.bool_)\n",
    "#     borders = np.pad(borders, pad_width=2, mode='constant', constant_values=1)\n",
    "#     for im in masks:\n",
    "#         tmp = mask.copy()\n",
    "#         tmp_borders = borders.copy()\n",
    "#         tmp[im] = False\n",
    "#         tmp_borders[im] = False\n",
    "#         dilated_im = scipy.ndimage.binary_dilation(im)\n",
    "#         intersection = (\n",
    "#             (scipy.ndimage.binary_dilation(tmp) & dilated_im) |\n",
    "#             (tmp_borders & scipy.ndimage.binary_dilation(dilated_im))\n",
    "#         )\n",
    "#         imask[intersection] = -1.5\n",
    "#     np.save(path + '/mask_ibn', imask)\n",
    "\n",
    "\n",
    "# glob_areas = list()\n",
    "# for n, path in tqdm(enumerate(train_paths), total=len(train_paths)):\n",
    "\n",
    "#     masks = list()\n",
    "#     for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "#         masks.append(scipy.misc.imread(path + '/masks/' + mask_file) > 0)\n",
    "\n",
    "#     mask = np.array(masks).max(0)\n",
    "#     imask = mask.copy().astype(np.float)\n",
    "#     borders = np.zeros(np.array(imask.shape) - 4, dtype=np.bool_)\n",
    "#     borders = np.pad(borders, pad_width=2, mode='constant', constant_values=1)\n",
    "    \n",
    "#     areas = list()\n",
    "#     for im in masks:\n",
    "#         areas.append(im.sum())\n",
    "        \n",
    "#     mean = np.median(areas)\n",
    "#     for i, im in enumerate(masks):\n",
    "#         tmp = mask.copy()\n",
    "#         tmp[im] = False\n",
    "#         tmp_borders = borders.copy()\n",
    "#         tmp_borders[im] = False\n",
    "#         dilated_im = scipy.ndimage.binary_dilation(im)\n",
    "#         intersection = (\n",
    "#             (scipy.ndimage.binary_dilation(tmp) & dilated_im) |\n",
    "#             (tmp_borders & scipy.ndimage.binary_dilation(dilated_im))\n",
    "#         )\n",
    "\n",
    "#         weight = (mean / intersection.sum()) ** (2 / 3)\n",
    "#         imask[intersection] = -1 * weight\n",
    "\n",
    "#     for i, im in enumerate(masks):\n",
    "#         residual_im = im & (imask > 0)\n",
    "#         imask[residual_im] = mean / residual_im.sum()\n",
    "\n",
    "#     np.save(path + '/mask_ibn_rel', imask)\n",
    "#     glob_areas.append(areas)\n",
    "\n",
    "\n",
    "sizes_train = dict()\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, path in tqdm(enumerate(train_paths), total=len(train_paths)):\n",
    "    img = scipy.misc.imread(os.path.join(path, 'images', os.path.basename(path) + '.png'))[..., :IMG_CHANNELS]\n",
    "    sizes_train[path] = ([img.shape[0], img.shape[1]])\n",
    "    \n",
    "\n",
    "sizes_test = dict()\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, path in tqdm(enumerate(test_paths), total=len(test_paths)):\n",
    "    img = scipy.misc.imread(os.path.join(path, 'images', os.path.basename(path) + '.png'))[..., :IMG_CHANNELS]\n",
    "    sizes_test[path] = ([img.shape[0], img.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle.dump(std_paths, open('../data/test_std_paths.pkl', 'wb'))\n",
    "std_paths = pickle.load(open('../data/std_paths.pkl', 'rb'))\n",
    "test_std_paths = pickle.load(open('../data/test_std_paths.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path[0] for path in std_paths]\n",
    "rs = np.random.RandomState(seed=12)\n",
    "rs.shuffle(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_15 = list()\n",
    "preds_ib = list()\n",
    "imgs = list()\n",
    "for path in test_paths:\n",
    "    x = [\n",
    "        np.load(os.path.join(path, 'borders_mask_elu16_bce1dice_soft_merging_LB_34_zoom_x_1.3.npy'))]\n",
    "    y = np.load(os.path.join(path, 'borders_mask_elu16_bce1dice_soft_merging_LB_34.npy'))\n",
    "#     x = np.mean([y, scipy.ndimage.zoom(x, 1 / 1.3)], axis=0)\n",
    "#     plt.imshow((x[..., 0] > .95) ^ (y[..., 0] > .95))\n",
    "#     plt.show()\n",
    "    preds_15.append(y)\n",
    "    preds_ib.append(np.load(os.path.join(path, 'filled_mask_elu16_bce1dice_soft_merging_LB_34.npy')))\n",
    "    imgs.append(load(path, test_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seeds = list()\n",
    "for img, pred9, pred5 in zip(imgs, preds_15, preds_ib):\n",
    "    p9, colours9 = scipy.ndimage.label(pred9 > .9)\n",
    "    p5, colours5 = scipy.ndimage.label(pred5 > .5)\n",
    "    if colours5 <= 8:\n",
    "        seeds.append(p5)\n",
    "        continue\n",
    "    for c5 in range(1, colours5 + 1):\n",
    "        roi = p9[p5 == c5]\n",
    "        roi = np.unique(roi[roi != 0])\n",
    "        if len(roi) == 0:\n",
    "            continue\n",
    "        if len(roi) == 1:\n",
    "            p9[p5 == c5] = roi[0]\n",
    "        else:\n",
    "            free_area = (p5 == c5) & np.logical_not(p9 > 0)\n",
    "            while free_area.sum():\n",
    "                for c9 in roi:\n",
    "                    cp9_dilated = scipy.ndimage.binary_dilation(p9 == c9)\n",
    "                    p9[free_area & cp9_dilated] = c9\n",
    "                    free_area = free_area & np.logical_not(cp9_dilated)\n",
    "                    \n",
    "    seeds.append(p9)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "#     plt.imshow(seeds[-1][..., 0])\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b > prev + 1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x):\n",
    "    for colour in range(1, x.max() + 1):\n",
    "        yield rle_encoding(x == colour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "65it [00:01, 51.29it/s]\n"
     ]
    }
   ],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, path in tqdm(enumerate(test_paths)):\n",
    "    rle = list(prob_to_rles(seeds[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([os.path.basename(path)] * len(rle))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('../data/dsb18.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
